#!/usr/bin/env python3
"""
æ•æ„Ÿè¿ç¦è¯å®¡æŸ¥å‘˜ Agent - æ£€æµ‹æ•æ„Ÿè¯ã€è¿ç¦è¯ã€è¿è§„å†…å®¹

åŠŸèƒ½ï¼š
- ç›‘å¬ content.tagged äº‹ä»¶è‡ªåŠ¨å®¡æŸ¥
- æ”¯æŒ @ è§¦å‘ï¼šåœ¨ã€Œåˆ›ä½œå·¥åŠã€é¢‘é“ @æ•æ„Ÿè¯å®¡æŸ¥ å®¡æŸ¥æœ€è¿‘æ–‡ç« 
- æ£€æµ‹æ”¿æ²»æ•æ„Ÿã€å¹¿å‘Šè¿ç¦è¯ã€ä½ä¿—å†…å®¹ç­‰
- ç»™å‡ºåˆè§„è¯„åˆ†å’Œä¿®æ”¹å»ºè®®
"""

import asyncio
import re
import sys
from pathlib import Path
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent.parent.parent / "src"))
sys.path.insert(0, str(Path(__file__).parent.parent))

from openagents.agents.worker_agent import WorkerAgent, on_event
from openagents.models.event import Event
from tools.llm_client import get_llm_client
from tools.database import get_database
from config.prompts import critic_technical
import logging

logger = logging.getLogger(__name__)


class SensitiveWordReviewerAgent(WorkerAgent):
    """æ•æ„Ÿè¿ç¦è¯å®¡æŸ¥å‘˜ Agent - å†…å®¹åˆè§„å®¡æŸ¥"""

    default_agent_id = "æ•æ„Ÿè¯å®¡æŸ¥"
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.llm = get_llm_client()
        self.db = get_database()
    
    async def on_startup(self):
        """Agent å¯åŠ¨æ—¶æ‰§è¡Œ"""
        logger.info("Sensitive Word Reviewer Agent started")

        await self._send_channel_message(
            "é€šç”¨é¢‘é“",
            "ğŸš« æ•æ„Ÿè¯å®¡æŸ¥å‘˜å·²ä¸Šçº¿ï¼\n"
            "ğŸ“ åœ¨ã€Œåˆ›ä½œå·¥åŠã€é¢‘é“ @æ•æ„Ÿè¯å®¡æŸ¥ å³å¯è·å¾—å†…å®¹åˆè§„å®¡æŸ¥"
        )

    async def on_shutdown(self):
        """Agent å…³é—­æ—¶æ‰§è¡Œ"""
        logger.info("Sensitive Word Reviewer Agent stopped")

    # ========== @ è§¦å‘åŠŸèƒ½ ==========

    @on_event("thread.channel_message.notification")
    async def handle_mention(self, context):
        """
        å¤„ç† @ æ¶ˆæ¯
        å½“ç”¨æˆ·åœ¨åˆ›ä½œå·¥åŠ @æ•æ„Ÿè¯å®¡æŸ¥ æ—¶è§¦å‘
        """
        try:
            # è·å–æ¶ˆæ¯æ•°æ®
            payload = context.incoming_event.payload
            channel = payload.get('channel', '')
            text = payload.get('content', {}).get('text', '').strip()
            user_id = payload.get('source_id', '')

            # åªå¤„ç†åˆ›ä½œå·¥åŠé¢‘é“
            if channel != 'åˆ›ä½œå·¥åŠ':
                return

            # å¿½ç•¥è‡ªå·±çš„æ¶ˆæ¯
            if user_id == 'æ•æ„Ÿè¯å®¡æŸ¥':
                return

            # æ£€æŸ¥æ˜¯å¦ @ äº†æ•æ„Ÿè¯å®¡æŸ¥
            if not self._is_mentioned(text):
                return

            logger.info(f"ğŸ“¨ æ”¶åˆ° @ æ¶ˆæ¯: user={user_id}, text={text[:50]}...")

            # è·å–æœ€è¿‘çš„æ–‡ç« 
            draft = await self._get_latest_draft()

            if not draft:
                await self._send_channel_message(
                    "åˆ›ä½œå·¥åŠ",
                    "ğŸ“­ æš‚æ—¶æ²¡æœ‰æ‰¾åˆ°æœ€è¿‘çš„æ–‡ç« å“¦~\n"
                    "ğŸ’¡ å…ˆåˆ›ä½œä¸€ç¯‡æ–‡ç« ï¼Œç„¶åå†æ¥æ‰¾æˆ‘å®¡æŸ¥å§ï¼"
                )
                return

            # é€šçŸ¥ç”¨æˆ·æ­£åœ¨å®¡æŸ¥
            await self._send_channel_message(
                "åˆ›ä½œå·¥åŠ",
                f"ğŸš« æ­£åœ¨è¿›è¡Œæ•æ„Ÿè¿ç¦è¯å®¡æŸ¥ã€Œ{draft.get('title', 'æœªå‘½å')}ã€...\n"
                f"â±ï¸ è¯·ç¨å€™ï¼Œé©¬ä¸Šç»™å‡ºå®¡æŸ¥ç»“æœ~"
            )

            # ç”Ÿæˆå®¡æŸ¥ç»“æœ
            review_data = await self._generate_draft_review(draft)

            if review_data:
                # å‘é€å®¡æŸ¥ç»“æœ
                await self._post_draft_review(draft, review_data)
                logger.info(f"âœ… æ•æ„Ÿè¯å®¡æŸ¥å®Œæˆ: {draft.get('title', 'N/A')}")
            else:
                await self._send_channel_message(
                    "åˆ›ä½œå·¥åŠ",
                    "âŒ æ•æ„Ÿè¯å®¡æŸ¥å¤±è´¥ï¼Œè¯·ç¨åå†è¯•"
                )

        except Exception as e:
            logger.error(f"âŒ å¤„ç† @ æ¶ˆæ¯å¤±è´¥: {e}", exc_info=True)
            await self._send_channel_message("åˆ›ä½œå·¥åŠ", f"âŒ å®¡æŸ¥å¤±è´¥: {str(e)}")

    def _is_mentioned(self, text: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦è¢« @ äº†"""
        patterns = [
            r'@æ•æ„Ÿè¯å®¡æŸ¥',
            r'@æ•æ„Ÿè¯',
            r'@è¿ç¦è¯',
            r'@åˆè§„',
        ]
        for pattern in patterns:
            if re.search(pattern, text, re.IGNORECASE):
                return True
        return False

    async def _get_latest_draft(self) -> dict:
        """è·å–æœ€è¿‘å®Œæˆçš„æ–‡ç« """
        try:
            conn = self.db._get_connection()
            cursor = conn.cursor()
            cursor.execute("""
                SELECT * FROM drafts
                WHERE status = 'completed'
                ORDER BY created_at DESC
                LIMIT 1
            """)
            row = cursor.fetchone()
            conn.close()
            if row:
                return self.db._row_to_dict(row)
            return None
        except Exception as e:
            logger.error(f"è·å–æœ€è¿‘æ–‡ç« å¤±è´¥: {e}")
            return None

    async def _generate_draft_review(self, draft: dict) -> dict:
        """ä¸ºæ–‡ç« è‰ç¨¿ç”Ÿæˆæ•æ„Ÿè¯å®¡æŸ¥"""
        try:
            title = draft.get('title', 'æœªå‘½å')
            content = draft.get('content', '')
            word_count = draft.get('word_count', 0)

            # æ„å»ºå®¡æŸ¥æç¤ºè¯
            system_prompt = critic_technical.SYSTEM_PROMPT
            user_prompt = f"""è¯·å¯¹ä»¥ä¸‹è‡ªåª’ä½“æ–‡ç« è¿›è¡Œæ•æ„Ÿè¿ç¦è¯å®¡æŸ¥ï¼š

**æ ‡é¢˜**: {title}
**å­—æ•°**: {word_count}

**æ–‡ç« å†…å®¹**:
{content[:3000]}

{'...(å†…å®¹å·²æˆªå–)' if len(content) > 3000 else ''}

è¯·ä»”ç»†æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ•æ„Ÿè¯ã€è¿ç¦è¯ã€è¿è§„è¡¨è¿°ç­‰é—®é¢˜ã€‚"""

            # è°ƒç”¨ LLM
            result = await self.llm.generate_json(
                system_prompt=system_prompt,
                user_prompt=user_prompt,
                temperature=0.7,
                max_tokens=8000
            )

            return result

        except Exception as e:
            logger.error(f"ç”Ÿæˆæ•æ„Ÿè¯å®¡æŸ¥å¤±è´¥: {e}")
            return None

    async def _post_draft_review(self, draft: dict, review_data: dict):
        """å‘å¸ƒæ–‡ç« è‰ç¨¿çš„æ•æ„Ÿè¯å®¡æŸ¥æŠ¥å‘Š"""
        try:
            title = draft.get('title', 'æœªå‘½å')
            scores = review_data.get('scores', {})
            overall = review_data.get('overall_score', 0)
            strengths = review_data.get('strengths', [])
            weaknesses = review_data.get('weaknesses', [])
            sensitive_words = review_data.get('sensitive_words', [])
            risk_areas = review_data.get('risk_areas', [])
            recommendations = review_data.get('recommendations', [])
            verdict = review_data.get('verdict', '')

            # æ„å»ºå®¡æŸ¥æŠ¥å‘Š
            review_text = f"# ğŸš« æ•æ„Ÿè¿ç¦è¯å®¡æŸ¥æŠ¥å‘Š\n\n"
            review_text += f"**æ–‡ç« **: ã€Š{title}ã€‹\n\n"
            review_text += f"## ğŸ“Š åˆè§„è¯„åˆ†\n\n"
            review_text += f"- **æ”¿æ²»åˆè§„**: {scores.get('political_compliance', 0)}/10\n"
            review_text += f"- **å¹¿å‘Šåˆè§„**: {scores.get('ad_compliance', 0)}/10\n"
            review_text += f"- **å†…å®¹å¥åº·**: {scores.get('content_health', 0)}/10\n"
            review_text += f"- **è¡¨è¿°è§„èŒƒ**: {scores.get('expression_standard', 0)}/10\n\n"
            review_text += f"**ç»¼åˆè¯„åˆ†**: {overall}/10\n\n"

            if strengths:
                review_text += f"## âœ… åˆè§„äº®ç‚¹\n\n"
                for s in strengths:
                    review_text += f"- {s}\n"
                review_text += "\n"

            if sensitive_words:
                review_text += f"## ğŸš¨ æ•æ„Ÿè¯æ£€æµ‹\n\n"
                for sw in sensitive_words[:5]:
                    word = sw.get('word', '')
                    location = sw.get('location', '')
                    risk = sw.get('risk_level', '')
                    suggestion = sw.get('suggestion', '')
                    review_text += f"- **{word}** ({location}) - é£é™©:{risk}\n"
                    review_text += f"  å»ºè®®: {suggestion}\n"
                review_text += "\n"

            if risk_areas:
                review_text += f"## âš ï¸ é£é™©é¢†åŸŸ\n\n"
                for r in risk_areas:
                    review_text += f"- {r}\n"
                review_text += "\n"

            if recommendations:
                review_text += f"## ğŸ’¡ ä¿®æ”¹å»ºè®®\n\n"
                for r in recommendations:
                    review_text += f"- {r}\n"
                review_text += "\n"

            review_text += f"## ğŸ“ å®¡æŸ¥ç»“è®º\n\n{verdict}\n"
            review_text += f"\n---\n*ğŸš« æ•æ„Ÿè¯å®¡æŸ¥å‘˜*"

            await self._send_channel_message("åˆ›ä½œå·¥åŠ", review_text)

        except Exception as e:
            logger.error(f"å‘å¸ƒæ•æ„Ÿè¯å®¡æŸ¥æŠ¥å‘Šå¤±è´¥: {e}")

    # ========== åˆ›ä½œå·¥åŠæ–‡ç« è‡ªåŠ¨å®¡æŸ¥ ==========

    @on_event("creation.draft_ready")
    async def handle_draft_ready(self, context):
        """
        è‡ªåŠ¨å®¡æŸ¥åˆ›ä½œå·¥åŠå®Œæˆçš„æ–‡ç« 
        å½“ Writer å®Œæˆæ–‡ç« åè‡ªåŠ¨è§¦å‘
        """
        try:
            event_data = context.incoming_event.payload
            draft = event_data.get('draft', {})
            session_id = event_data.get('session_id')
            draft_id = event_data.get('draft_id')

            if not draft:
                logger.warning("æ”¶åˆ° creation.draft_ready ä½†æ²¡æœ‰ draft æ•°æ®")
                return

            title = draft.get('title', 'æœªå‘½å')
            logger.info(f"ğŸš« è‡ªåŠ¨å®¡æŸ¥åˆ›ä½œæ–‡ç« : {title}")

            # ç”Ÿæˆå®¡æŸ¥
            review_data = await self._generate_draft_review(draft)

            if review_data:
                # ä¸ç›´æ¥å‘é€è¯¦ç»†æŠ¥å‘Šï¼Œè€Œæ˜¯é€šè¿‡äº‹ä»¶ä¼ é€’å®Œæ•´æ•°æ®
                # ç”± creation_coordinator ç»Ÿä¸€æ§åˆ¶è¾“å‡º

                # å‘é€å®¡æŸ¥å®Œæˆäº‹ä»¶ï¼ˆåŒ…å«å®Œæ•´å®¡æŸ¥æ•°æ®ç”¨äºæ±‡æ€»å’ŒæŒ‰éœ€å±•ç¤ºï¼‰
                await self.send_event(Event(
                    event_name="creation.review_completed",
                    source_id=self.agent_id,
                    payload={
                        "session_id": session_id,
                        "draft_id": draft_id,
                        "review_type": "sensitive",
                        "overall_score": review_data.get('overall_score', 0),
                        "verdict": review_data.get('verdict', ''),
                        "suggestions": review_data.get('recommendations', []),
                        # ä¼ é€’å®Œæ•´å®¡æŸ¥æ•°æ®ç”¨äºæŒ‰éœ€å±•ç¤ºè¯¦ç»†æŠ¥å‘Š
                        "full_review": review_data,
                        "draft_title": title
                    }
                ))

                logger.info(f"âœ… æ•æ„Ÿè¯è‡ªåŠ¨å®¡æŸ¥å®Œæˆ: {title}")
            else:
                logger.error(f"âŒ æ•æ„Ÿè¯è‡ªåŠ¨å®¡æŸ¥å¤±è´¥: {title}")

        except Exception as e:
            logger.error(f"âŒ å¤„ç† creation.draft_ready å¤±è´¥: {e}", exc_info=True)

    # ========== RSS å†…å®¹è‡ªåŠ¨è¯„å®¡åŠŸèƒ½ ==========

    @on_event("content.tagged")
    async def handle_content_tagged(self, event):
        """å¤„ç† content.tagged äº‹ä»¶"""
        try:
            payload = event.get("payload", {})
            content_id = payload.get("content_id")
            
            if not content_id:
                logger.warning("Received event without content_id")
                return
            
            logger.info(f"Reviewing content from technical perspective: {content_id}")
            
            # è·å–å†…å®¹
            content_data = self.db.get_content(content_id)
            if not content_data:
                logger.error(f"Content not found: {content_id}")
                return
            
            # ç”ŸæˆæŠ€æœ¯è¯„å®¡
            review_data = await self._generate_review(content_data)
            
            if review_data:
                # å‘é€åˆ° Forumï¼ˆç¨åå®ç°ï¼‰
                await self._post_review_to_forum(content_data, review_data)
                
                # å‘é€äº‹ä»¶é€šçŸ¥å…¶ä»– Agent
                await self._emit_review_completed(content_id, "technical", review_data)
                
                logger.info(f"Technical review completed for: {content_id}")
            else:
                logger.error(f"Failed to generate technical review for: {content_id}")
        
        except Exception as e:
            logger.error(f"Error handling content.tagged: {str(e)}")
    
    async def _generate_review(self, content_data: dict) -> dict:
        """
        ç”ŸæˆæŠ€æœ¯è¯„å®¡
        
        Returns:
            è¯„å®¡æ•°æ®å­—å…¸ï¼Œå¤±è´¥è¿”å› None
        """
        try:
            title = content_data['title']
            source = content_data.get('source', 'Unknown')
            category = content_data.get('category', 'tech')
            summary = content_data.get('summary_paragraph', '')
            key_points = content_data.get('key_points', [])
            
            if not summary:
                logger.warning(f"No summary available for technical review: {title}")
                return None
            
            # æ ¼å¼åŒ–æç¤ºè¯
            system_prompt, user_prompt = critic_technical.format_prompt(
                title=title,
                source=source,
                category=category,
                summary=summary,
                key_points=key_points
            )
            
            # è°ƒç”¨ LLM
            logger.info(f"Calling LLM for technical review: {title}")
            result = await self.llm.generate_json(
                system_prompt=system_prompt,
                user_prompt=user_prompt,
                temperature=0.7,
                max_tokens=8000
            )
            
            if not result:
                logger.error("LLM returned empty result")
                return None
            
            # éªŒè¯è¿”å›çš„å­—æ®µ
            required_fields = ['scores', 'overall_score', 'verdict']
            if not all(field in result for field in required_fields):
                logger.error(f"Missing required fields in LLM response: {result.keys()}")
                return None
            
            logger.info(f"Technical review completed with score: {result['overall_score']}")
            return result
            
        except Exception as e:
            logger.error(f"Error generating technical review: {str(e)}")
            return None
    
    async def _post_review_to_forum(self, content_data: dict, review_data: dict):
        """å°†è¯„å®¡å‘å¸ƒåˆ° Forum"""
        try:
            title = content_data['title']
            scores = review_data.get('scores', {})
            overall = review_data.get('overall_score', 0)
            strengths = review_data.get('strengths', [])
            weaknesses = review_data.get('weaknesses', [])
            concerns = review_data.get('technical_concerns', [])
            recommendations = review_data.get('recommendations', [])
            verdict = review_data.get('verdict', '')
            
            # æ„å»ºè¯„å®¡å†…å®¹
            review_text = f"# ğŸ”§ æŠ€æœ¯è¯„å®¡æŠ¥å‘Š\n\n"
            review_text += f"**å†…å®¹**: {title}\n\n"
            review_text += f"## ğŸ“Š è¯„åˆ†è¯¦æƒ…\n\n"
            review_text += f"- **æŠ€æœ¯å‡†ç¡®æ€§**: {scores.get('accuracy', 0)}/10\n"
            review_text += f"- **æ·±åº¦è¯„åˆ†**: {scores.get('depth', 0)}/10\n"
            review_text += f"- **å®ç”¨æ€§**: {scores.get('practicality', 0)}/10\n"
            review_text += f"- **åˆ›æ–°æ€§**: {scores.get('innovation', 0)}/10\n\n"
            review_text += f"**ç»¼åˆè¯„åˆ†**: {overall}/10\n\n"
            
            if strengths:
                review_text += f"## âœ… æŠ€æœ¯ä¼˜åŠ¿\n\n"
                for s in strengths:
                    review_text += f"- {s}\n"
                review_text += "\n"
            
            if weaknesses:
                review_text += f"## âš ï¸ æŠ€æœ¯ä¸è¶³\n\n"
                for w in weaknesses:
                    review_text += f"- {w}\n"
                review_text += "\n"
            
            if concerns:
                review_text += f"## ğŸš¨ æŠ€æœ¯å…³æ³¨ç‚¹\n\n"
                for c in concerns:
                    review_text += f"- {c}\n"
                review_text += "\n"
            
            if recommendations:
                review_text += f"## ğŸ’¡ æ”¹è¿›å»ºè®®\n\n"
                for r in recommendations:
                    review_text += f"- {r}\n"
                review_text += "\n"
            
            review_text += f"## ğŸ“ æ€»ç»“\n\n{verdict}\n"
            
            # æš‚æ—¶å‘é€åˆ°é¢‘é“ï¼ˆForum åŠŸèƒ½ç¨åå®ç°ï¼‰
            await self._send_channel_message("åˆ›ä½œå·¥åŠ", review_text)
            
        except Exception as e:
            logger.error(f"Error posting review to forum: {str(e)}")
    
    async def _emit_review_completed(self, content_id: str, review_type: str, review_data: dict):
        """å‘é€è¯„å®¡å®Œæˆäº‹ä»¶"""
        try:
            event = Event(
                event_name="content.reviewed",
                source_id=self.agent_id,
                payload={
                    "content_id": content_id,
                    "review_type": review_type,
                    "overall_score": review_data.get('overall_score'),
                    "verdict": review_data.get('verdict')
                }
            )
            await self.send_event(event)
            logger.info(f"Emitted content.reviewed event for: {content_id}")
        except Exception as e:
            logger.error(f"Failed to emit content.reviewed event: {str(e)}")
    
    async def _send_channel_message(self, channel: str, text: str):
        """å‘é€é¢‘é“æ¶ˆæ¯"""
        try:
            messaging = self.client.mod_adapters.get("openagents.mods.workspace.messaging")
            if messaging:
                await messaging.send_channel_message(
                    channel=channel,
                    text=text
                )
        except Exception as e:
            logger.error(f"Failed to send channel message: {str(e)}")


async def main():
    """è¿è¡Œ Sensitive Word Reviewer Agent"""
    import argparse

    parser = argparse.ArgumentParser(description="Sensitive Word Reviewer Agent")
    parser.add_argument("--host", default="localhost", help="Network host")
    parser.add_argument("--port", type=int, default=8700, help="Network port")
    args = parser.parse_args()

    # é…ç½®æ—¥å¿—
    log_file = Path(__file__).parent.parent / 'logs' / 'agents' / 'critic_sensitive.log'
    log_file.parent.mkdir(parents=True, exist_ok=True)

    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, mode='a'),
            logging.StreamHandler(sys.stdout)
        ],
        force=True
    )

    sys.stdout.reconfigure(line_buffering=True)
    sys.stderr.reconfigure(line_buffering=True)

    agent = SensitiveWordReviewerAgent()

    try:
        await agent.async_start(
            network_host=args.host,
            network_port=args.port,
        )

        logger.info(f"Sensitive Word Reviewer Agent running. Press Ctrl+C to stop.")

        while True:
            await asyncio.sleep(1)

    except KeyboardInterrupt:
        logger.info("\nShutting down...")
    finally:
        await agent.async_stop()


if __name__ == "__main__":
    asyncio.run(main())