#!/usr/bin/env python3
"""
AIå‘³å®¡æŸ¥å‘˜ Agent - æ£€æµ‹AIç”Ÿæˆç—•è¿¹ï¼Œæå‡å†…å®¹äººå‘³

åŠŸèƒ½ï¼š
- ç›‘å¬ content.tagged äº‹ä»¶è‡ªåŠ¨å®¡æŸ¥
- æ”¯æŒ @ è§¦å‘ï¼šåœ¨ã€Œåˆ›ä½œå·¥åŠã€é¢‘é“ @AIå‘³å®¡æŸ¥ å®¡æŸ¥æœ€è¿‘æ–‡ç« 
- æ£€æµ‹AIç”Ÿæˆç—•è¿¹ã€è¯­è¨€è‡ªç„¶åº¦ã€æƒ…æ„ŸçœŸå®æ€§ç­‰
- ç»™å‡ºäººæ€§åŒ–æ”¹å†™å»ºè®®
"""

import asyncio
import re
import sys
from pathlib import Path
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent.parent.parent / "src"))
sys.path.insert(0, str(Path(__file__).parent.parent))

from openagents.agents.worker_agent import WorkerAgent, on_event
from openagents.models.event import Event
from tools.llm_client import get_llm_client
from tools.database import get_database
from config.prompts import critic_business
import logging

logger = logging.getLogger(__name__)


class AIFlavorReviewerAgent(WorkerAgent):
    """AIå‘³å®¡æŸ¥å‘˜ Agent - æ£€æµ‹AIç—•è¿¹æå‡äººå‘³"""

    default_agent_id = "AIå‘³å®¡æŸ¥"
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.llm = get_llm_client()
        self.db = get_database()
    
    async def on_startup(self):
        """Agent å¯åŠ¨æ—¶æ‰§è¡Œ"""
        logger.info("AI Flavor Reviewer Agent started")

        await self._send_channel_message(
            "é€šç”¨é¢‘é“",
            "ğŸ¤– AIå‘³å®¡æŸ¥å‘˜å·²ä¸Šçº¿ï¼\n"
            "ğŸ“ åœ¨ã€Œåˆ›ä½œå·¥åŠã€é¢‘é“ @AIå‘³å®¡æŸ¥ å³å¯æ£€æµ‹å†…å®¹çš„AIç—•è¿¹"
        )

    async def on_shutdown(self):
        """Agent å…³é—­æ—¶æ‰§è¡Œ"""
        logger.info("AI Flavor Reviewer Agent stopped")

    # ========== @ è§¦å‘åŠŸèƒ½ ==========

    @on_event("thread.channel_message.notification")
    async def handle_mention(self, context):
        """
        å¤„ç† @ æ¶ˆæ¯
        å½“ç”¨æˆ·åœ¨åˆ›ä½œå·¥åŠ @AIå‘³å®¡æŸ¥ æ—¶è§¦å‘
        """
        try:
            # è·å–æ¶ˆæ¯æ•°æ®
            payload = context.incoming_event.payload
            channel = payload.get('channel', '')
            text = payload.get('content', {}).get('text', '').strip()
            user_id = payload.get('source_id', '')

            # åªå¤„ç†åˆ›ä½œå·¥åŠé¢‘é“
            if channel != 'åˆ›ä½œå·¥åŠ':
                return

            # å¿½ç•¥è‡ªå·±çš„æ¶ˆæ¯
            if user_id == 'AIå‘³å®¡æŸ¥':
                return

            # æ£€æŸ¥æ˜¯å¦ @ äº†AIå‘³å®¡æŸ¥
            if not self._is_mentioned(text):
                return

            logger.info(f"ğŸ“¨ æ”¶åˆ° @ æ¶ˆæ¯: user={user_id}, text={text[:50]}...")

            # è·å–æœ€è¿‘çš„æ–‡ç« 
            draft = await self._get_latest_draft()

            if not draft:
                await self._send_channel_message(
                    "åˆ›ä½œå·¥åŠ",
                    "ğŸ“­ æš‚æ—¶æ²¡æœ‰æ‰¾åˆ°æœ€è¿‘çš„æ–‡ç« å“¦~\n"
                    "ğŸ’¡ å…ˆåˆ›ä½œä¸€ç¯‡æ–‡ç« ï¼Œç„¶åå†æ¥æ‰¾æˆ‘å®¡æŸ¥å§ï¼"
                )
                return

            # é€šçŸ¥ç”¨æˆ·æ­£åœ¨å®¡æŸ¥
            await self._send_channel_message(
                "åˆ›ä½œå·¥åŠ",
                f"ğŸ¤– æ­£åœ¨è¿›è¡ŒAIå‘³å®¡æŸ¥ã€Œ{draft.get('title', 'æœªå‘½å')}ã€...\n"
                f"â±ï¸ è¯·ç¨å€™ï¼Œé©¬ä¸Šç»™å‡ºå®¡æŸ¥ç»“æœ~"
            )

            # ç”Ÿæˆå®¡æŸ¥ç»“æœ
            review_data = await self._generate_draft_review(draft)

            if review_data:
                # å‘é€å®¡æŸ¥ç»“æœ
                await self._post_draft_review(draft, review_data)
                logger.info(f"âœ… AIå‘³å®¡æŸ¥å®Œæˆ: {draft.get('title', 'N/A')}")
            else:
                await self._send_channel_message(
                    "åˆ›ä½œå·¥åŠ",
                    "âŒ AIå‘³å®¡æŸ¥å¤±è´¥ï¼Œè¯·ç¨åå†è¯•"
                )

        except Exception as e:
            logger.error(f"âŒ å¤„ç† @ æ¶ˆæ¯å¤±è´¥: {e}", exc_info=True)
            await self._send_channel_message("åˆ›ä½œå·¥åŠ", f"âŒ å®¡æŸ¥å¤±è´¥: {str(e)}")

    def _is_mentioned(self, text: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦è¢« @ äº†"""
        patterns = [
            r'@AIå‘³å®¡æŸ¥',
            r'@AIå‘³',
            r'@äººå‘³',
            r'@åŸåˆ›',
        ]
        for pattern in patterns:
            if re.search(pattern, text, re.IGNORECASE):
                return True
        return False

    async def _get_latest_draft(self) -> dict:
        """è·å–æœ€è¿‘å®Œæˆçš„æ–‡ç« """
        try:
            conn = self.db._get_connection()
            cursor = conn.cursor()
            cursor.execute("""
                SELECT * FROM drafts
                WHERE status = 'completed'
                ORDER BY created_at DESC
                LIMIT 1
            """)
            row = cursor.fetchone()
            conn.close()
            if row:
                return self.db._row_to_dict(row)
            return None
        except Exception as e:
            logger.error(f"è·å–æœ€è¿‘æ–‡ç« å¤±è´¥: {e}")
            return None

    async def _generate_draft_review(self, draft: dict) -> dict:
        """ä¸ºæ–‡ç« è‰ç¨¿ç”ŸæˆAIå‘³å®¡æŸ¥"""
        try:
            title = draft.get('title', 'æœªå‘½å')
            content = draft.get('content', '')
            word_count = draft.get('word_count', 0)

            # æ„å»ºå®¡æŸ¥æç¤ºè¯
            system_prompt = critic_business.SYSTEM_PROMPT
            user_prompt = f"""è¯·å¯¹ä»¥ä¸‹è‡ªåª’ä½“æ–‡ç« è¿›è¡ŒAIå‘³å®¡æŸ¥ï¼š

**æ ‡é¢˜**: {title}
**å­—æ•°**: {word_count}

**æ–‡ç« å†…å®¹**:
{content[:3000]}

{'...(å†…å®¹å·²æˆªå–)' if len(content) > 3000 else ''}

è¯·æ£€æµ‹æ–‡ç« çš„AIç”Ÿæˆç—•è¿¹ï¼Œå¹¶ç»™å‡ºäººæ€§åŒ–æ”¹å†™å»ºè®®ã€‚"""

            # è°ƒç”¨ LLM
            result = await self.llm.generate_json(
                system_prompt=system_prompt,
                user_prompt=user_prompt,
                temperature=0.7,
                max_tokens=8000
            )

            return result

        except Exception as e:
            logger.error(f"ç”ŸæˆAIå‘³å®¡æŸ¥å¤±è´¥: {e}")
            return None

    async def _post_draft_review(self, draft: dict, review_data: dict):
        """å‘å¸ƒæ–‡ç« è‰ç¨¿çš„AIå‘³å®¡æŸ¥æŠ¥å‘Š"""
        try:
            title = draft.get('title', 'æœªå‘½å')
            scores = review_data.get('scores', {})
            overall = review_data.get('overall_score', 0)
            strengths = review_data.get('strengths', [])
            weaknesses = review_data.get('weaknesses', [])
            ai_indicators = review_data.get('ai_indicators', [])
            humanization_tips = review_data.get('humanization_tips', [])
            rewrite_suggestions = review_data.get('rewrite_suggestions', [])
            verdict = review_data.get('verdict', '')

            # æ„å»ºå®¡æŸ¥æŠ¥å‘Š
            review_text = f"# ğŸ¤– AIå‘³å®¡æŸ¥æŠ¥å‘Š\n\n"
            review_text += f"**æ–‡ç« **: ã€Š{title}ã€‹\n\n"
            review_text += f"## ğŸ“Š äººå‘³è¯„åˆ†\n\n"
            review_text += f"- **åŸåˆ›æ€§**: {scores.get('originality', 0)}/10\n"
            review_text += f"- **è‡ªç„¶åº¦**: {scores.get('naturalness', 0)}/10\n"
            review_text += f"- **æƒ…æ„Ÿåº¦**: {scores.get('emotionality', 0)}/10\n"
            review_text += f"- **å£è¯­åŒ–**: {scores.get('colloquialism', 0)}/10\n\n"
            review_text += f"**ç»¼åˆè¯„åˆ†**: {overall}/10\n\n"

            if strengths:
                review_text += f"## âœ… äººå‘³äº®ç‚¹\n\n"
                for s in strengths:
                    review_text += f"- {s}\n"
                review_text += "\n"

            if ai_indicators:
                review_text += f"## ğŸš¨ AIç—•è¿¹æ£€æµ‹\n\n"
                for ai in ai_indicators[:5]:
                    indicator = ai.get('indicator', '')
                    examples = ai.get('examples', [])
                    severity = ai.get('severity', '')
                    review_text += f"- **{indicator}** (ä¸¥é‡åº¦:{severity})\n"
                    if examples:
                        review_text += f"  ç¤ºä¾‹: {', '.join(examples[:2])}\n"
                review_text += "\n"

            if rewrite_suggestions:
                review_text += f"## âœï¸ æ”¹å†™å»ºè®®\n\n"
                for rw in rewrite_suggestions[:3]:
                    original = rw.get('original', '')
                    suggested = rw.get('suggested', '')
                    review_text += f"- åŸæ–‡: ã€Œ{original}ã€\n"
                    review_text += f"  æ”¹ä¸º: ã€Œ{suggested}ã€\n"
                review_text += "\n"

            if humanization_tips:
                review_text += f"## ğŸ’¡ äººæ€§åŒ–æŠ€å·§\n\n"
                for tip in humanization_tips[:5]:
                    review_text += f"- {tip}\n"
                review_text += "\n"

            review_text += f"## ğŸ“ å®¡æŸ¥ç»“è®º\n\n{verdict}\n"
            review_text += f"\n---\n*ğŸ¤– AIå‘³å®¡æŸ¥å‘˜*"

            await self._send_channel_message("åˆ›ä½œå·¥åŠ", review_text)

        except Exception as e:
            logger.error(f"å‘å¸ƒAIå‘³å®¡æŸ¥æŠ¥å‘Šå¤±è´¥: {e}")

    # ========== åˆ›ä½œå·¥åŠæ–‡ç« è‡ªåŠ¨å®¡æŸ¥ ==========

    @on_event("creation.draft_ready")
    async def handle_draft_ready(self, context):
        """
        è‡ªåŠ¨å®¡æŸ¥åˆ›ä½œå·¥åŠå®Œæˆçš„æ–‡ç« 
        å½“ Writer å®Œæˆæ–‡ç« åè‡ªåŠ¨è§¦å‘
        """
        try:
            event_data = context.incoming_event.payload
            draft = event_data.get('draft', {})
            session_id = event_data.get('session_id')
            draft_id = event_data.get('draft_id')

            if not draft:
                logger.warning("æ”¶åˆ° creation.draft_ready ä½†æ²¡æœ‰ draft æ•°æ®")
                return

            title = draft.get('title', 'æœªå‘½å')
            logger.info(f"ğŸ¤– è‡ªåŠ¨å®¡æŸ¥åˆ›ä½œæ–‡ç« : {title}")

            # ç”Ÿæˆå®¡æŸ¥
            review_data = await self._generate_draft_review(draft)

            if review_data:
                # ä¸ç›´æ¥å‘é€è¯¦ç»†æŠ¥å‘Šï¼Œè€Œæ˜¯é€šè¿‡äº‹ä»¶ä¼ é€’å®Œæ•´æ•°æ®
                # ç”± creation_coordinator ç»Ÿä¸€æ§åˆ¶è¾“å‡º

                # å‘é€å®¡æŸ¥å®Œæˆäº‹ä»¶ï¼ˆåŒ…å«å®Œæ•´å®¡æŸ¥æ•°æ®ç”¨äºæ±‡æ€»å’ŒæŒ‰éœ€å±•ç¤ºï¼‰
                await self.send_event(Event(
                    event_name="creation.review_completed",
                    source_id=self.agent_id,
                    payload={
                        "session_id": session_id,
                        "draft_id": draft_id,
                        "review_type": "ai_flavor",
                        "overall_score": review_data.get('overall_score', 0),
                        "verdict": review_data.get('verdict', ''),
                        "suggestions": review_data.get('humanization_tips', []),
                        # ä¼ é€’å®Œæ•´å®¡æŸ¥æ•°æ®ç”¨äºæŒ‰éœ€å±•ç¤ºè¯¦ç»†æŠ¥å‘Š
                        "full_review": review_data,
                        "draft_title": title
                    }
                ))

                logger.info(f"âœ… AIå‘³è‡ªåŠ¨å®¡æŸ¥å®Œæˆ: {title}")
            else:
                logger.error(f"âŒ AIå‘³è‡ªåŠ¨å®¡æŸ¥å¤±è´¥: {title}")

        except Exception as e:
            logger.error(f"âŒ å¤„ç† creation.draft_ready å¤±è´¥: {e}", exc_info=True)

    # ========== RSS å†…å®¹è‡ªåŠ¨è¯„å®¡åŠŸèƒ½ ==========

    @on_event("content.tagged")
    async def handle_content_tagged(self, event):
        """å¤„ç† content.tagged äº‹ä»¶"""
        try:
            payload = event.get("payload", {})
            content_id = payload.get("content_id")
            
            if not content_id:
                logger.warning("Received event without content_id")
                return
            
            logger.info(f"Reviewing content from business perspective: {content_id}")
            
            # è·å–å†…å®¹
            content_data = self.db.get_content(content_id)
            if not content_data:
                logger.error(f"Content not found: {content_id}")
                return
            
            # ç”Ÿæˆå•†ä¸šè¯„å®¡
            review_data = await self._generate_review(content_data)
            
            if review_data:
                # å‘é€åˆ° Forum
                await self._post_review_to_forum(content_data, review_data)
                
                # å‘é€äº‹ä»¶é€šçŸ¥å…¶ä»– Agent
                await self._emit_review_completed(content_id, "business", review_data)
                
                logger.info(f"Business review completed for: {content_id}")
            else:
                logger.error(f"Failed to generate business review for: {content_id}")
        
        except Exception as e:
            logger.error(f"Error handling content.tagged: {str(e)}")
    
    async def _generate_review(self, content_data: dict) -> dict:
        """ç”Ÿæˆå•†ä¸šè¯„å®¡"""
        try:
            title = content_data['title']
            source = content_data.get('source', 'Unknown')
            category = content_data.get('category', 'tech')
            summary = content_data.get('summary_paragraph', '')
            key_points = content_data.get('key_points', [])
            
            if not summary:
                logger.warning(f"No summary available for business review: {title}")
                return None
            
            # æ ¼å¼åŒ–æç¤ºè¯
            system_prompt, user_prompt = critic_business.format_prompt(
                title=title,
                source=source,
                category=category,
                summary=summary,
                key_points=key_points
            )
            
            # è°ƒç”¨ LLM
            logger.info(f"Calling LLM for business review: {title}")
            result = await self.llm.generate_json(
                system_prompt=system_prompt,
                user_prompt=user_prompt,
                temperature=0.7,
                max_tokens=8000
            )
            
            if not result:
                logger.error("LLM returned empty result")
                return None
            
            logger.info(f"Business review completed with score: {result.get('overall_score', 0)}")
            return result
            
        except Exception as e:
            logger.error(f"Error generating business review: {str(e)}")
            return None
    
    async def _post_review_to_forum(self, content_data: dict, review_data: dict):
        """å°†è¯„å®¡å‘å¸ƒåˆ° Forum"""
        try:
            title = content_data['title']
            scores = review_data.get('scores', {})
            overall = review_data.get('overall_score', 0)
            strengths = review_data.get('strengths', [])
            weaknesses = review_data.get('weaknesses', [])
            market_analysis = review_data.get('market_analysis', {})
            concerns = review_data.get('business_concerns', [])
            recommendations = review_data.get('recommendations', [])
            verdict = review_data.get('verdict', '')
            
            # æ„å»ºè¯„å®¡å†…å®¹
            review_text = f"# ğŸ’¼ å•†ä¸šåˆ†ææŠ¥å‘Š\n\n"
            review_text += f"**å†…å®¹**: {title}\n\n"
            review_text += f"## ğŸ“Š å•†ä¸šè¯„åˆ†\n\n"
            review_text += f"- **å•†ä¸šæ½œåŠ›**: {scores.get('business_potential', 0)}/10\n"
            review_text += f"- **ç«äº‰åŠ›**: {scores.get('competitiveness', 0)}/10\n"
            review_text += f"- **å˜ç°èƒ½åŠ›**: {scores.get('monetization', 0)}/10\n"
            review_text += f"- **å¸‚åœºæ—¶æœº**: {scores.get('market_timing', 0)}/10\n\n"
            review_text += f"**ç»¼åˆè¯„åˆ†**: {overall}/10\n\n"
            
            if market_analysis:
                review_text += f"## ğŸ¯ å¸‚åœºåˆ†æ\n\n"
                review_text += f"- **ç›®æ ‡å¸‚åœº**: {market_analysis.get('target_market', 'N/A')}\n"
                review_text += f"- **å¸‚åœºè§„æ¨¡**: {market_analysis.get('market_size', 'N/A')}\n"
                review_text += f"- **ç«äº‰ç¨‹åº¦**: {market_analysis.get('competition', 'N/A')}\n\n"
            
            if strengths:
                review_text += f"## âœ… å•†ä¸šä¼˜åŠ¿\n\n"
                for s in strengths:
                    review_text += f"- {s}\n"
                review_text += "\n"
            
            if weaknesses:
                review_text += f"## âš ï¸ å•†ä¸šæŒ‘æˆ˜\n\n"
                for w in weaknesses:
                    review_text += f"- {w}\n"
                review_text += "\n"
            
            if concerns:
                review_text += f"## ğŸš¨ å…³é”®é—®é¢˜\n\n"
                for c in concerns:
                    review_text += f"- {c}\n"
                review_text += "\n"
            
            if recommendations:
                review_text += f"## ğŸ’¡ æˆ˜ç•¥å»ºè®®\n\n"
                for r in recommendations:
                    review_text += f"- {r}\n"
                review_text += "\n"
            
            review_text += f"## ğŸ“ æ€»ç»“\n\n{verdict}\n"
            
            await self._send_channel_message("åˆ›ä½œå·¥åŠ", review_text)
            
        except Exception as e:
            logger.error(f"Error posting review to forum: {str(e)}")
    
    async def _emit_review_completed(self, content_id: str, review_type: str, review_data: dict):
        """å‘é€è¯„å®¡å®Œæˆäº‹ä»¶"""
        try:
            event = Event(
                event_name="content.reviewed",
                source_id=self.agent_id,
                payload={
                    "content_id": content_id,
                    "review_type": review_type,
                    "overall_score": review_data.get('overall_score'),
                    "verdict": review_data.get('verdict')
                }
            )
            await self.send_event(event)
            logger.info(f"Emitted content.reviewed event for: {content_id}")
        except Exception as e:
            logger.error(f"Failed to emit content.reviewed event: {str(e)}")
    
    async def _send_channel_message(self, channel: str, text: str):
        """å‘é€é¢‘é“æ¶ˆæ¯"""
        try:
            messaging = self.client.mod_adapters.get("openagents.mods.workspace.messaging")
            if messaging:
                await messaging.send_channel_message(
                    channel=channel,
                    text=text
                )
        except Exception as e:
            logger.error(f"Failed to send channel message: {str(e)}")


async def main():
    """è¿è¡Œ AI Flavor Reviewer Agent"""
    import argparse

    parser = argparse.ArgumentParser(description="AI Flavor Reviewer Agent")
    parser.add_argument("--host", default="localhost", help="Network host")
    parser.add_argument("--port", type=int, default=8700, help="Network port")
    args = parser.parse_args()

    # é…ç½®æ—¥å¿—
    log_file = Path(__file__).parent.parent / 'logs' / 'agents' / 'critic_ai_flavor.log'
    log_file.parent.mkdir(parents=True, exist_ok=True)

    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, mode='a'),
            logging.StreamHandler(sys.stdout)
        ],
        force=True
    )

    sys.stdout.reconfigure(line_buffering=True)
    sys.stderr.reconfigure(line_buffering=True)

    agent = AIFlavorReviewerAgent()

    try:
        await agent.async_start(
            network_host=args.host,
            network_port=args.port,
        )

        logger.info(f"AI Flavor Reviewer Agent running. Press Ctrl+C to stop.")

        while True:
            await asyncio.sleep(1)

    except KeyboardInterrupt:
        logger.info("\nShutting down...")
    finally:
        await agent.async_stop()


if __name__ == "__main__":
    asyncio.run(main())