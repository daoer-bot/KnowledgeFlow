"""
å†…å®¹åŒæ­¥å·¥å…· - å°† content_items åŒæ­¥åˆ° Wiki
"""

import asyncio
import logging
from typing import List, Dict, Any, Optional
from datetime import datetime

logger = logging.getLogger(__name__)


class ContentSyncTool:
    """å°† content_items æ•°æ®åº“å†…å®¹åŒæ­¥åˆ° Wiki"""

    def __init__(self, db, workspace_client=None):
        """
        åˆå§‹åŒ–åŒæ­¥å·¥å…·

        Args:
            db: Database å®ä¾‹
            workspace_client: Workspace å®¢æˆ·ç«¯ï¼ˆç”¨äºå‘é€ Wiki äº‹ä»¶ï¼‰
        """
        self.db = db
        self.workspace_client = workspace_client

    async def sync_all_to_wiki(self, limit: int = 100) -> Dict[str, Any]:
        """
        åŒæ­¥æ‰€æœ‰å·²å¤„ç†çš„å†…å®¹åˆ° Wiki

        Args:
            limit: æœ€å¤§åŒæ­¥æ•°é‡

        Returns:
            åŒæ­¥ç»“æœç»Ÿè®¡
        """
        conn = self.db._get_connection()
        cursor = conn.cursor()

        # è·å–å·²å¤„ç†ä½†æœªåŒæ­¥çš„å†…å®¹
        cursor.execute("""
            SELECT * FROM content_items
            WHERE status = 'processed'
            ORDER BY collected_at DESC
            LIMIT ?
        """, (limit,))

        rows = cursor.fetchall()
        conn.close()

        results = {
            'total': len(rows),
            'synced': 0,
            'failed': 0,
            'skipped': 0
        }

        for row in rows:
            content = self.db._row_to_dict(row)
            try:
                success = await self._sync_content_to_wiki(content)
                if success:
                    results['synced'] += 1
                else:
                    results['skipped'] += 1
            except Exception as e:
                logger.error(f"åŒæ­¥å¤±è´¥: {content.get('title', 'N/A')} - {e}")
                results['failed'] += 1

        logger.info(f"åŒæ­¥å®Œæˆ: {results}")
        return results

    async def _sync_content_to_wiki(self, content: Dict[str, Any]) -> bool:
        """
        åŒæ­¥å•æ¡å†…å®¹åˆ° Wiki

        Args:
            content: å†…å®¹æ•°æ®

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            content_id = content.get('id', '')
            title = content.get('title', 'N/A')
            source = content.get('source', 'æœªçŸ¥')
            category = content.get('category', 'tech')
            summary = content.get('summary_paragraph', '')
            key_points = content.get('key_points', [])
            tags = content.get('tags', [])
            url = content.get('url', '')
            collected_at = content.get('collected_at', '')

            # æ„å»º Wiki é¡µé¢å†…å®¹
            wiki_content = f"# {title}\n\n"
            wiki_content += f"**æ¥æº**: {source}\n"
            wiki_content += f"**åˆ†ç±»**: {category}\n"
            wiki_content += f"**æ”¶é›†æ—¶é—´**: {collected_at}\n"
            if url:
                wiki_content += f"**åŸæ–‡é“¾æ¥**: [{url}]({url})\n"
            wiki_content += "\n---\n\n"

            if summary:
                wiki_content += f"## æ‘˜è¦\n\n{summary}\n\n"

            if key_points:
                wiki_content += "## è¦ç‚¹\n\n"
                if isinstance(key_points, str):
                    import json
                    try:
                        key_points = json.loads(key_points)
                    except:
                        key_points = [key_points]
                for point in key_points:
                    wiki_content += f"- {point}\n"
                wiki_content += "\n"

            if tags:
                if isinstance(tags, str):
                    import json
                    try:
                        tags = json.loads(tags)
                    except:
                        tags = [tags]
                wiki_content += f"**æ ‡ç­¾**: {', '.join(tags)}\n"

            # ç”Ÿæˆå®‰å…¨çš„é¡µé¢è·¯å¾„
            import re
            safe_title = re.sub(r'[^\w\u4e00-\u9fff\-]', '_', title)[:80]
            page_path = f"materials/{category}/{safe_title}"

            # å¦‚æœæœ‰ workspace_clientï¼Œé€šè¿‡äº‹ä»¶å‘é€
            if self.workspace_client:
                from openagents.models.event import Event
                wiki_event = Event(
                    event_name="wiki.page.create",
                    source_id="content_sync",
                    target_agent_id="mod:openagents.mods.workspace.wiki",
                    payload={
                        "page_path": page_path,
                        "title": title,
                        "wiki_content": wiki_content,
                        "metadata": {
                            "content_id": content_id,
                            "source": source,
                            "category": category
                        }
                    },
                    visibility="network"
                )
                await self.workspace_client.send_event(wiki_event)
                logger.info(f"âœ… å·²å‘é€ Wiki åŒæ­¥äº‹ä»¶: {title}")
                return True
            else:
                # ç›´æ¥å†™å…¥æ•°æ®åº“ï¼ˆå¦‚æœ Wiki mod ä¸å¯ç”¨ï¼‰
                logger.warning(f"âš ï¸ æ—  workspace_clientï¼Œè·³è¿‡: {title}")
                return False

        except Exception as e:
            logger.error(f"åŒæ­¥å†…å®¹å¤±è´¥: {e}")
            return False

    def get_sync_status(self) -> Dict[str, int]:
        """è·å–åŒæ­¥çŠ¶æ€ç»Ÿè®¡"""
        conn = self.db._get_connection()
        cursor = conn.cursor()

        cursor.execute("""
            SELECT status, COUNT(*) as count
            FROM content_items
            GROUP BY status
        """)

        rows = cursor.fetchall()
        conn.close()

        return {row['status']: row['count'] for row in rows}


async def sync_content_to_wiki_cli():
    """å‘½ä»¤è¡ŒåŒæ­¥å·¥å…·"""
    import argparse
    from tools.database import get_database

    parser = argparse.ArgumentParser(description="åŒæ­¥ content_items åˆ° Wiki")
    parser.add_argument("--limit", type=int, default=50, help="æœ€å¤§åŒæ­¥æ•°é‡")
    parser.add_argument("--dry-run", action="store_true", help="ä»…æ˜¾ç¤ºå°†è¦åŒæ­¥çš„å†…å®¹")
    args = parser.parse_args()

    logging.basicConfig(level=logging.INFO)

    db = get_database()
    sync_tool = ContentSyncTool(db)

    if args.dry_run:
        # ä»…æ˜¾ç¤ºçŠ¶æ€
        status = sync_tool.get_sync_status()
        print("\nğŸ“Š å†…å®¹çŠ¶æ€ç»Ÿè®¡:")
        for s, count in status.items():
            print(f"  - {s}: {count}")

        conn = db._get_connection()
        cursor = conn.cursor()
        cursor.execute("""
            SELECT title, source, category FROM content_items
            WHERE status = 'processed'
            ORDER BY collected_at DESC
            LIMIT ?
        """, (args.limit,))
        rows = cursor.fetchall()
        conn.close()

        print(f"\nğŸ“ å°†è¦åŒæ­¥çš„å†…å®¹ (å‰ {args.limit} æ¡):")
        for i, row in enumerate(rows, 1):
            print(f"  {i}. [{row['category']}] {row['title'][:50]}... ({row['source']})")
    else:
        print("âš ï¸ éœ€è¦åœ¨ Agent ç¯å¢ƒä¸­è¿è¡Œæ‰èƒ½åŒæ­¥åˆ° Wiki")
        print("ğŸ’¡ è¯·ä½¿ç”¨ --dry-run æŸ¥çœ‹å°†è¦åŒæ­¥çš„å†…å®¹")


if __name__ == "__main__":
    asyncio.run(sync_content_to_wiki_cli())
